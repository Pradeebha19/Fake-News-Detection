{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB  # Import MultinomialNB\n",
        "from sklearn.svm import SVC  # Import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "ALxpA0b1nx7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = pd.read_csv(\"/content/Fake.csv\")\n",
        "real = pd.read_csv(\"/content/True.csv\")\n"
      ],
      "metadata": {
        "id": "l8aBU9Een4om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake['label'] = 1\n",
        "real['label'] = 0\n"
      ],
      "metadata": {
        "id": "zOmADjZVoACZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([fake, real], ignore_index=True)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "qKM3sZBRoCpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(rf\"[{re.escape(string.punctuation)}]\", '', text)\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "6OZ5Wz78oI62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "X = tfidf.fit_transform(df['cleaned_text'])\n",
        "y = df['label']\n"
      ],
      "metadata": {
        "id": "Bt8NKDsRoc2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OPM_swEAxGBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "QZ-3jP-_xIVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "VQpd3cg6yotH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "}"
      ],
      "metadata": {
        "id": "jsP_phfjzpy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grids = {\n",
        "    'Logistic Regression': {\n",
        "        'clf__C': [0.1, 1, 10]\n",
        "    },\n",
        "    'Naive Bayes': {\n",
        "        'clf__alpha': [0.5, 1.0, 1.5]\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "KrzL0kB1zzud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install scikit-learn\n",
        "# Import Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV # Make sure GridSearchCV is also imported\n"
      ],
      "metadata": {
        "id": "mNBjyxrqz_mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    print(f\"\\nüîç Training and tuning {name}...\")\n",
        "    pipeline = Pipeline([\n",
        "        # ('tfidf', TfidfVectorizer(max_features=5000)),  # Remove this line\n",
        "        ('clf', model)\n",
        "    ])\n",
        "\n",
        "    # Update param_grid to reflect the removal of 'tfidf'\n",
        "    grid_params = param_grids[name]\n",
        "    # grid_params['tfidf__max_features'] = [5000]  #  If you want to tune max_features\n",
        "\n",
        "    grid = GridSearchCV(pipeline, grid_params, cv=3, n_jobs=-1, verbose=1)\n",
        "    grid.fit(X_train, y_train)  # X_train is already transformed\n",
        "\n",
        "    print(f\"‚úÖ Best Parameters for {name}: {grid.best_params_}\")\n",
        "    y_pred = grid.predict(X_test)\n",
        "\n",
        "    print(f\"\\nüìä Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(\"\\nüìã Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"üßÆ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uMRW89JWz3Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define pipeline without TfidfVectorizer\n",
        "rf_pipeline = Pipeline([\n",
        "    ('clf', RandomForestClassifier(random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "KEm4jcvjYgLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {\n",
        "    'clf__n_estimators': [100, 200],\n",
        "    'clf__max_depth': [None, 10, 20],\n",
        "    'clf__min_samples_split': [2, 5]\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "p9Cm1J7CZlo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid = GridSearchCV(rf_pipeline, rf_params, cv=3, n_jobs=-1, verbose=1)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\nüå≤ Random Forest Classifier Results:\")\n",
        "print(f\"Best Params: {rf_grid.best_params_}\")\n",
        "y_pred_rf = rf_grid.predict(X_test)\n"
      ],
      "metadata": {
        "id": "PAWwyor2ZqCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üìä Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"\\nüìã Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"üßÆ Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "OYfdZdWSlIzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save\n",
        "joblib.dump(rf_grid.best_estimator_, \"best_fake_news_model.pkl\")\n",
        "\n",
        "# Load later\n",
        "# model = joblib.load(\"best_fake_news_model.pkl\")\n"
      ],
      "metadata": {
        "id": "msn90ACtlsuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.show()\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.show()\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YSo9NVlhlvEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"cleaned_fake_news.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "SlvVYJ3-m1Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame({\n",
        "    'Text': X_test,\n",
        "    'Actual Label': y_test,\n",
        "    'Predicted Label': y_pred_rf\n",
        "})\n",
        "results_df.to_csv(\"model_results.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "pC5Hp1SYm4zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model_results.csv')  # triggers download popup\n"
      ],
      "metadata": {
        "id": "zHMUp5kOm9QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Fake.csv')\n",
        "# ... cleaning steps ...\n",
        "df['text'] = df['text'].apply(clean_text)  #"
      ],
      "metadata": {
        "id": "mE-NTiB9ufX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('cleaned_fake_news.csv', index=False)"
      ],
      "metadata": {
        "id": "VbG3_-S6uhkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('cleaned_fake_news.csv')"
      ],
      "metadata": {
        "id": "jgkaPKgKvHFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}